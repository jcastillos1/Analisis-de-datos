{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Paquetes !\n",
        "#---------------------------------------------------------\n",
        "import tensorflow as tf\n",
        "import random as rd\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "metadata": {
        "id": "j9tpew-7sF3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar set de datos de tensorflow_datasets\n",
        "datos, metadatos = tfds.load('cifar10_1', as_supervised=True,with_info=True)\n",
        "datos_entrenamiento, datos_pruebas = datos['test'], datos['test']\n",
        "nombres_clases = ['spring', 'summer', 'autumn', 'winter']\n",
        "\n",
        "# Funcion de normalizacion para los datos (Pasar de 0-255 a 0-1). Hace que la red aprenda mejor y mas rapido\n",
        "def normalizar(imagenes, etiquetas):\n",
        "  imagenes = tf.cast(imagenes, tf.float32)\n",
        "  imagenes /= 255 #Aqui lo pasa de 0-255 a 0-1\n",
        "  return imagenes, etiquetas\n",
        "\n",
        "# Normalizar los datos de entrenamiento y agrega a cach√© en vez del disco, entrenamiento mas rapido\n",
        "datos_entrenamiento = datos_entrenamiento.map(normalizar); datos_pruebas = datos_pruebas.map(normalizar)\n",
        "datos_entrenamiento = datos_entrenamiento.cache(); datos_pruebas = datos_pruebas.cache()\n",
        "\n",
        "# Crear el modelo\n",
        "modelo = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28,28,1)), #1 - blanco y negro\n",
        "  tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) #Para redes de clasificacion\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Mostrar imagenes\n",
        "plt.figure(figsize=(15,15)); cant_im=2021\n",
        "for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(cant_im)):\n",
        "  imagen = imagen[:28,:28,:].numpy()\n",
        "  plt.subplot(int(cant_im**(1/2)),round(cant_im**(1/2))+1,i+1);\n",
        "  plt.xticks([]); plt.yticks([])\n",
        "  plt.xlabel(nombres_clases[int(rd.uniform(0,3))])\n",
        "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9hcJAY5X4Vt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_entrenamiento.take(1)"
      ],
      "metadata": {
        "id": "3stS4G8cTnNb",
        "outputId": "8b4a2c08-191f-455a-ad82-99a8afe8b42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}